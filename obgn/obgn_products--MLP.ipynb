{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-vision",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.nn import Node2Vec\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-victor",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = PygNodePropPredDataset(name = \"ogbn-products\", root = 'dataset/')\n",
    "data = dataset[0]\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "breathing-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "political-fundamental",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_idx = dataset.get_idx_split()\n",
    "train_idx, valid_idx, test_idx = split_idx[\"train\"], split_idx[\"valid\"], split_idx[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strong-phrase",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-strategy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-dairy",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "g = to_networkx(data, to_undirected=True)\n",
    "nx.draw(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "preliminary-metabolism",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = data.x[train_idx]\n",
    "edge_index = data.edge_index[train_idx]\n",
    "small_data = torch_geometric.data.Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.num_node_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "public-bathroom",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-shirt",
   "metadata": {},
   "source": [
    "https://github.com/snap-stanford/ogb/blob/master/examples/nodeproppred/products/mlp.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "spare-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# from torch_geometric.nn import GCNConv, SAGEConv\n",
    "\n",
    "from ogb.nodeproppred import PygNodePropPredDataset, Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "raised-complaint",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, in_dim, hidden_dim, out_dim, num_layers, dropout):\n",
    "        \n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.linears = torch.nn.ModuleList()        \n",
    "        self.linears.append(torch.nn.Linear(in_dim, hidden_dim))\n",
    "        for _ in range(1, num_layers-1):\n",
    "            self.linears.append(torch.nn.Linear(hidden_dim, hidden_dim))\n",
    "        self.linears.append(torch.nn.Linear(hidden_dim, out_dim))\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        \n",
    "    \n",
    "    def reset_parameters(self):\n",
    "        \n",
    "        for lin in self.linears:\n",
    "            lin.reset_parameters()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        for lin in self.linears[:-1]:\n",
    "            x = lin(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, p=self.dropout, training=self.training)\n",
    "            \n",
    "        x = self.linears[-1](x)\n",
    "        x = torch.log_softmax(x, dim=-1)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "subjective-ghost",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, x, y_true, train_idx, optimizer, loss_fn):\n",
    "    \n",
    "    model.train()\n",
    "    loss = 0\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    pred = model(x[train_idx])\n",
    "    loss = loss_fn(pred, y_true.squeeze(1)[train_idx])\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, x, y_true, split_idx, evaluator):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    out = model(x)\n",
    "    y_pred = out.argmax(dim=-1, keepdim=True)\n",
    "    \n",
    "    train_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['train']],\n",
    "        'y_pred': y_pred[split_idx['train']]\n",
    "    })['acc']\n",
    "    \n",
    "    valid_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['valid']],\n",
    "        'y_pred': y_pred[split_idx['valid']]\n",
    "    })['acc']\n",
    "    \n",
    "    test_acc = evaluator.eval({\n",
    "        'y_true': y_true[split_idx['test']],\n",
    "        'y_pred': y_pred[split_idx['test']]\n",
    "    })['acc']\n",
    "    \n",
    "    return train_acc, valid_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "placed-elevation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(args):\n",
    "    \n",
    "    dataset = PygNodePropPredDataset(name='ogbn-products', root = 'dataset/')\n",
    "    split_idx = dataset.get_idx_split()\n",
    "    data = dataset[0]\n",
    "    \n",
    "    device = args['device']\n",
    "    use_node_embedding = args['use_node_embedding']\n",
    "\n",
    "    x = data.x\n",
    "    if use_node_embedding:\n",
    "        embedding = torch.load('embedding.pt', map_location='cpu')\n",
    "        x = torch.cat([x, embedding], dim=-1)\n",
    "\n",
    "    x = x.to(device)\n",
    "    y_true = data.y.to(device)\n",
    "    train_idx = split_idx['train'].to(device)\n",
    "    \n",
    "    return x, y_true, train_idx, split_idx, dataset.num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "pretty-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(x, num_classes, args):\n",
    "    \n",
    "    device = args['device']\n",
    "    \n",
    "    if args['model_name'] == 'MLP':\n",
    "        model = MLP(x.size(-1), args['hidden_dim'], num_classes, args['num_layers'], args['dropout']).to(device)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "disabled-tension",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, x, y_true, train_idx, split_idx, args):\n",
    "\n",
    "    evaluator = Evaluator(name='ogbn-products')\n",
    "\n",
    "    model.reset_parameters()\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=args['lr'])\n",
    "    loss_fn = F.nll_loss  # cross entropy = softmax + nll_loss，已經在 forward 裡面使用 softmax，因此這邊只用 nll_loss\n",
    "\n",
    "    best_model = None\n",
    "    best_valid_acc = 0\n",
    "\n",
    "    for epoch in range(args['epochs']):\n",
    "        loss = train(model, x, y_true, train_idx, optimizer, loss_fn)\n",
    "        result = test(model, x, y_true, split_idx, evaluator)\n",
    "\n",
    "        if epoch % args['log_steps'] == 0:\n",
    "            train_acc, valid_acc, test_acc = result\n",
    "            print(f'Epoch: {epoch:02d}, '\n",
    "                  f'Loss: {loss:.4f}, '\n",
    "                  f'Train: {100 * train_acc:.2f}%, '\n",
    "                  f'Valid: {100 * valid_acc:.2f}%, '\n",
    "                  f'Test: {100 * test_acc:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "liquid-repeat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    device = torch.device(device)\n",
    "\n",
    "    args = {\n",
    "        'device': device,\n",
    "        'num_layers': 3,\n",
    "        'hidden_dim': 256,\n",
    "        'dropout': 0.0,\n",
    "        'lr': 0.01,\n",
    "        'epochs': 300,\n",
    "        'log_steps': 10,\n",
    "        'use_node_embedding': False,\n",
    "        'model_name': 'MLP'\n",
    "    }\n",
    "    \n",
    "    x, y_true, train_idx, split_idx, num_classes = load_data(args)\n",
    "    \n",
    "    model = build_model(x, num_classes, args)\n",
    "    run_model(model, x, y_true, train_idx, split_idx, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "specified-match",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00, Loss: 3.8492, Train: 30.84%, Valid: 30.83%, Test: 26.94%\n",
      "Epoch: 10, Loss: 1.7212, Train: 55.96%, Valid: 55.10%, Test: 43.27%\n",
      "Epoch: 20, Loss: 1.3275, Train: 64.73%, Valid: 63.70%, Test: 51.65%\n",
      "Epoch: 30, Loss: 1.1348, Train: 69.13%, Valid: 67.91%, Test: 55.11%\n",
      "Epoch: 40, Loss: 1.0077, Train: 71.87%, Valid: 70.37%, Test: 57.07%\n",
      "Epoch: 50, Loss: 0.9154, Train: 74.16%, Valid: 72.15%, Test: 58.40%\n",
      "Epoch: 60, Loss: 0.8406, Train: 75.95%, Valid: 73.40%, Test: 59.58%\n",
      "Epoch: 70, Loss: 0.7805, Train: 77.43%, Valid: 74.15%, Test: 60.11%\n",
      "Epoch: 80, Loss: 0.7400, Train: 78.52%, Valid: 74.58%, Test: 60.46%\n",
      "Epoch: 90, Loss: 0.6969, Train: 79.64%, Valid: 74.95%, Test: 60.76%\n",
      "Epoch: 100, Loss: 0.6725, Train: 80.24%, Valid: 74.95%, Test: 60.85%\n",
      "Epoch: 110, Loss: 0.6409, Train: 81.08%, Valid: 75.20%, Test: 61.01%\n",
      "Epoch: 120, Loss: 0.6163, Train: 81.74%, Valid: 75.25%, Test: 60.92%\n",
      "Epoch: 130, Loss: 0.5999, Train: 82.06%, Valid: 75.10%, Test: 60.98%\n",
      "Epoch: 140, Loss: 0.5837, Train: 82.89%, Valid: 75.31%, Test: 61.02%\n",
      "Epoch: 150, Loss: 0.5667, Train: 82.99%, Valid: 75.22%, Test: 60.80%\n",
      "Epoch: 160, Loss: 0.5513, Train: 83.60%, Valid: 75.35%, Test: 61.07%\n",
      "Epoch: 170, Loss: 0.5432, Train: 83.83%, Valid: 75.37%, Test: 61.11%\n",
      "Epoch: 180, Loss: 0.5251, Train: 84.23%, Valid: 75.45%, Test: 61.07%\n",
      "Epoch: 190, Loss: 0.5172, Train: 84.55%, Valid: 75.39%, Test: 61.03%\n",
      "Epoch: 200, Loss: 0.5041, Train: 85.02%, Valid: 75.20%, Test: 60.86%\n",
      "Epoch: 210, Loss: 0.5256, Train: 83.72%, Valid: 74.86%, Test: 60.55%\n",
      "Epoch: 220, Loss: 0.5558, Train: 83.85%, Valid: 74.85%, Test: 60.67%\n",
      "Epoch: 230, Loss: 0.5040, Train: 85.26%, Valid: 75.19%, Test: 61.03%\n",
      "Epoch: 240, Loss: 0.4723, Train: 85.65%, Valid: 75.28%, Test: 60.91%\n",
      "Epoch: 250, Loss: 0.4624, Train: 86.21%, Valid: 75.30%, Test: 60.76%\n",
      "Epoch: 260, Loss: 0.4527, Train: 86.52%, Valid: 75.24%, Test: 60.95%\n",
      "Epoch: 270, Loss: 0.4447, Train: 86.76%, Valid: 75.25%, Test: 60.78%\n",
      "Epoch: 280, Loss: 0.4829, Train: 82.69%, Valid: 73.92%, Test: 59.90%\n",
      "Epoch: 290, Loss: 0.4616, Train: 84.94%, Valid: 75.15%, Test: 60.74%\n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sitting-argument",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "latest_PyG",
   "language": "python",
   "name": "latest_pyg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
